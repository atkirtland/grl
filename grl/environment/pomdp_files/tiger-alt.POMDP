# Adapted from http://pomdp.org/examples/tiger.aaai.POMDP
#
# Split tiger-left and tiger-right into two states each:
#   - L1 and R1 are the starting states
#   - L2 and R2 are only reachable by the listen action
# # #

# This is the tiger problem of AAAI paper fame in the new pomdp
# format.  This format is still experimental and subject to change

discount: 0.5
values: reward
states: l1 r1 l2 r2 terminal
actions: listen open-left open-right
observations: tiger-left tiger-right terminal

start:
0.5 0.5 0.0 0.0 0.0

T: listen
0.0 0.0 1.0 0.0 0.0
0.0 0.0 0.0 1.0 0.0
0.0 0.0 1.0 0.0 0.0
0.0 0.0 0.0 1.0 0.0
0.0 0.0 0.0 0.0 0.0

T: open-left
0.0 0.0 0.0 0.0 1.0
0.0 0.0 0.0 0.0 1.0
0.0 0.0 0.0 0.0 1.0
0.0 0.0 0.0 0.0 1.0
0.0 0.0 0.0 0.0 0.0

T: open-right
0.0 0.0 0.0 0.0 1.0
0.0 0.0 0.0 0.0 1.0
0.0 0.0 0.0 0.0 1.0
0.0 0.0 0.0 0.0 1.0
0.0 0.0 0.0 0.0 0.0

O: *
0.5 0.5 0.0
0.5 0.5 0.0
0.85 0.15 0.0
0.15 0.85 0.0
0.0 0.0 1.0

R: listen : * : * : * -1

R: open-left : l1 : * : * -100

R: open-left : l2 : * : * -100

R: open-left : r1 : * : * 10

R: open-left : r2 : * : * 10

R: open-right : l1 : * : * 10

R: open-right : l2 : * : * 10

R: open-right : r1 : * : * -100

R: open-right : r2 : * : * -100

Pi_phi:
0 1 0
0 1 0
0 0 0

Pi_phi:
0 0 1
0 0 1
0 0 0

Pi_phi:
0 1 0
0 0 1
0 0 0

Pi_phi:
0 0 1
0 1 0
0 0 0
