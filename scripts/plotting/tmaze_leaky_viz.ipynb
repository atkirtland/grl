{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "from jax.config import config\n",
        "import jax.numpy as jnp\n",
        "from jax.nn import softmax\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from grl.utils import load_info\n",
        "from definitions import ROOT_DIR\n",
        "config.update('jax_platform_name', 'cpu')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_mem_matrix(mem_params: jnp.ndarray, test_preserving: bool = True):\n",
        "    \"\"\"\n",
        "    Tests the memory matrix for t-maze.\n",
        "    our tolerance is set to 1e-1, which seems high, but should be fine for\n",
        "    stochastic matrices that we have.\n",
        "    \"\"\"\n",
        "    NORTH, SOUTH, EAST, WEST = list(range(4))\n",
        "    UP_START = 0\n",
        "    DOWN_START = 1\n",
        "    CORRIDOR = 2\n",
        "    JUNCTION = 3\n",
        "\n",
        "    mem_func = softmax(mem_params, axis=-1)\n",
        "    right_mem_func = mem_func[EAST]\n",
        "\n",
        "    # we index by zero here, since memory starts at 0\n",
        "    right_up_start = right_mem_func[UP_START, 0]\n",
        "    right_down_start = right_mem_func[DOWN_START, 0]\n",
        "\n",
        "    # we test whether start bits set to different memory states\n",
        "    def test_start_bits_set(right_up_start: np.ndarray, right_down_start: np.ndarray):\n",
        "        return np.isclose(np.abs(right_up_start - right_down_start).sum() / 2, 1, atol=1e-1)\n",
        "\n",
        "    diff_start_bits_set = test_start_bits_set(right_up_start, right_down_start)\n",
        "\n",
        "    # now we test whether the right corridor memory function is all set or reset\n",
        "    right_corridor = right_mem_func[CORRIDOR]\n",
        "\n",
        "    def test_corridor_hold_or_toggle(right_corridor: np.ndarray):\n",
        "        is_toggle = np.allclose(right_corridor, np.eye(2)[:, ::-1], atol=1e-1)\n",
        "        is_hold = np.allclose(right_corridor, np.eye(2), atol=1e-1)\n",
        "        return is_toggle, is_hold\n",
        "\n",
        "    def test_memory_preserving(mem: np.ndarray):\n",
        "        # everything that's not part of the optimal policy\n",
        "        # ie. check for memory preserving functions\n",
        "        corridor_bumps = mem[[NORTH, SOUTH], CORRIDOR]\n",
        "        corridor_left = mem[[WEST], CORRIDOR]\n",
        "\n",
        "        junction_bumps = mem[[EAST], JUNCTION]\n",
        "        junction_left = mem[[WEST], JUNCTION]\n",
        "        all_checks = {'corridor_bumps': corridor_bumps, 'corridor_left': corridor_left, 'junction_bumps': junction_bumps, 'junction_left': junction_left}\n",
        "        is_preserving = np.allclose(np.concatenate(tuple(all_checks.values()), axis=0), np.eye(2), atol=1e-2)\n",
        "        return is_preserving, all_checks\n",
        "\n",
        "    is_toggle, is_hold = test_corridor_hold_or_toggle(right_corridor)\n",
        "\n",
        "    is_optimal = diff_start_bits_set and (is_toggle or is_hold)\n",
        "    additional_info = {'diff_start_bits_set': diff_start_bits_set, 'is_toggle': is_toggle, 'is_hold': is_hold}\n",
        "    if test_preserving:\n",
        "        is_preserving, all_preserving_checks = test_memory_preserving(mem_func)\n",
        "\n",
        "        is_optimal = is_optimal and is_preserving\n",
        "        additional_info.update(all_preserving_checks)\n",
        "\n",
        "    return is_optimal, additional_info\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sampled_results(pathname: str, use_epsilon: bool = False):\n",
        "    all_results = []\n",
        "    results_dirs = glob.glob(pathname)\n",
        "    for results_dir in results_dirs:\n",
        "        results_file = results_dir + '/info.npy'\n",
        "        if not os.path.exists(results_file):\n",
        "            continue\n",
        "        info = load_info(results_file)\n",
        "        final_mem_params = info['final_params']\n",
        "        is_optimal, mem_info = test_mem_matrix(final_mem_params, test_preserving=use_epsilon)\n",
        "        result = {\n",
        "            'policy_up_prob': info['policy_up_prob'],\n",
        "            'policy_epsilon': info['policy_epsilon'] if 'policy_epsilon' in info else np.nan,\n",
        "            'trial_id': os.path.basename(results_dir).split('__')[0].split('_')[-1],\n",
        "            'initial_discrep': info['initial_discrep'],\n",
        "            'final_discrep': info['final_discrep'],\n",
        "            'is_optimal': is_optimal\n",
        "        }\n",
        "        all_results.append(result)\n",
        "    data = pd.DataFrame(all_results)\n",
        "    return data\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_analytical_results(pathname: str, use_epsilon=False):\n",
        "    results_dir = Path(ROOT_DIR, pathname)\n",
        "\n",
        "    def aggregate_q_discrep(q_discrep, policy):\n",
        "        return (q_discrep.T * policy).sum(-1).mean()\n",
        "\n",
        "    all_results = []\n",
        "    for results_path in results_dir.iterdir():\n",
        "        if results_path.suffix != '.npy':\n",
        "            continue\n",
        "        info = load_info(results_path)\n",
        "        args = info['args']\n",
        "\n",
        "        policy_up_prob = args['tmaze_junction_up_pi']\n",
        "        policy_epsilon = args['epsilon'] if 'epsilon' in args else np.nan\n",
        "\n",
        "        grad_info = info['logs']\n",
        "        args = info['args']\n",
        "        agent_info = load_info(results_path.parent/'agents'/f'{results_path.stem}.pkl.npy')\n",
        "        final_mem_params = agent_info.mem_params\n",
        "        is_optimal, additional_checks = test_mem_matrix(final_mem_params, test_preserving=use_epsilon)\n",
        "\n",
        "        initial_q_discrep = grad_info['initial_mem_stats']['discrep'].item()\n",
        "        final_q_discrep = grad_info['final_mem_stats']['discrep'].item()\n",
        "\n",
        "        result = {\n",
        "            'policy_up_prob': policy_up_prob,\n",
        "            'policy_epsilon': policy_epsilon,\n",
        "            'mem_id': args['use_memory'],\n",
        "            'leak': args['mem_leakiness'],\n",
        "            'trial_id': os.path.basename(results_path).split('_s(')[-1].split(')_')[0],\n",
        "            'seed': args['seed'],\n",
        "            # 'initial_discrep': initial_v_discrep.mean(),\n",
        "            # 'final_discrep': final_v_discrep.mean(),\n",
        "            'initial_discrep': initial_q_discrep,\n",
        "            'final_discrep': final_q_discrep,\n",
        "            'is_optimal': is_optimal,\n",
        "        }\n",
        "        all_results.append(result)\n",
        "    data = pd.DataFrame(all_results)\n",
        "    return data\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sweep(data: pd.DataFrame, x='policy_up_prob', ax=None, title=None, add_colorbar=False):\n",
        "    y_high = max(data['initial_discrep'].max(), data['final_discrep'].max()) * 1.05\n",
        "    y_low = 0\n",
        "    x_high = max(data[x])\n",
        "    x_low = min(data[x])\n",
        "\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(7, 5))\n",
        "    data_seed_avg = data.groupby(x, as_index=False).mean()\n",
        "    aximg = ax.imshow(\n",
        "        data_seed_avg['is_optimal'].to_numpy()[None, :],\n",
        "        vmin=0,\n",
        "        vmax=1,\n",
        "        extent=(x_low, x_high, y_low, y_high),\n",
        "        cmap='RdYlBu',\n",
        "        aspect='auto',\n",
        "        alpha=0.5,\n",
        "    )\n",
        "    if add_colorbar:\n",
        "        plt.gcf().colorbar(aximg,\n",
        "                           label='Optimal memory frequency',\n",
        "                           ticks=[0.0, 0.5, 1.0],\n",
        "                           format='%0.1f')\n",
        "    sns.lineplot(data=data, x=x, y='initial_discrep', color='blue', ax=ax, label='Initial')\n",
        "    sns.lineplot(data=data, x=x, y='final_discrep', color='black', ax=ax, label='Final')\n",
        "    ax.legend()\n",
        "    ax.set_ylabel('Aggregated Î»-discrep')\n",
        "    ax.set_xlabel(x)\n",
        "    ax.set_title(title)\n",
        "    plt.gcf().tight_layout()\n",
        "    plt.gcf().subplots_adjust(right=0.75)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# planning_data = load_analytical_results(str(Path(ROOT_DIR, 'results', 'tmaze_sweep_junction_pi')))\n",
        "# learning_data = load_sampled_results(\n",
        "#     str(Path(ROOT_DIR, 'results', 'junction-up-prob-lambda999-6', 'tmaze_5_two_thirds_up/*')))\n",
        "planning_data = load_analytical_results(str(Path(ROOT_DIR, 'results', 'tmaze_sweep_junction_pi_leaky')))\n",
        "# learning_data = load_sampled_results(\n",
        "#     str(Path(ROOT_DIR, 'results', 'sweep-up-prob-imp-samp-7', 'tmaze_5_two_thirds_up/*')))\n",
        "\n",
        "np.set_printoptions(precision=4)\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "leaks = planning_data['leak'].unique()\n",
        "leaks.sort()\n",
        "for leak in leaks:\n",
        "    fig, axes = plt.subplots(1, 1, figsize=(12, 5))\n",
        "    plot_sweep(planning_data[planning_data['leak'] == leak], ax=axes, title=f'Planning Agent, leak={leak:.2f}', add_colorbar=False)\n",
        "    axes.set_xlim(0,0.5)\n",
        "# plot_sweep(learning_data, ax=axes[1], title='Learning Agent', add_colorbar=True)\n",
        "# learning_data[learning_data['policy_up_prob'] == 0]\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# planning_data = load_analytical_results(pathname=str(Path(ROOT_DIR, 'results', 'tmaze_sweep_eps')), use_epsilon=True)\n",
        "# learning_data = load_sampled_results(\n",
        "#     str(Path(ROOT_DIR, 'results', 'junction-sweep-eps-lambda999-03', 'tmaze_5_two_thirds_up/*')))\n",
        "planning_data = load_analytical_results(pathname=str(Path(ROOT_DIR, 'results', 'tmaze_sweep_eps_leaky')), use_epsilon=True)\n",
        "# learning_data = load_sampled_results(\n",
        "#     str(Path(ROOT_DIR, 'results', 'sweep-eps-imp-samp-04', 'tmaze_5_two_thirds_up/*')))\n",
        "\n",
        "leaks = planning_data['leak'].unique()\n",
        "leaks.sort()\n",
        "fig, axes = plt.subplots(1, 1, figsize=(8, 5))\n",
        "for leak in leaks:\n",
        "    plot_sweep(planning_data[planning_data['leak'] == leak], ax=axes, x='policy_epsilon', title=f'Planning Agent, leak={leak:.2f}', add_colorbar=False)\n",
        "# plot_sweep(learning_data, ax=axes[1], x='policy_epsilon', title='Learning Agent', add_colorbar=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.plot()\n",
        "sns.lineplot(data=planning_data, ax=ax, x='policy_epsilon', y='initial_discrep', color='blue', linestyle='-', label='Initial, Planning')\n",
        "sns.lineplot(data=learning_data, ax=ax, x='policy_epsilon', y='initial_discrep', color='blue', linestyle='--', label='Initial, Learning')\n",
        "sns.lineplot(data=planning_data, ax=ax, x='policy_epsilon', y='final_discrep', color='black', linestyle='-', label='Final, Planning')\n",
        "sns.lineplot(data=learning_data, ax=ax, x='policy_epsilon', y='final_discrep', color='black', linestyle='--', label='Final, Learning')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planning_data = load_analytical_results('results/analytical/tmaze_sweep_junction_pi_2022-02-17')\n",
        "learning_data = load_sampled_results(\n",
        "    'results/sample_based/junction-sweep-up-prob-5/tmaze_5_two_thirds_up/*')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.plot()\n",
        "sns.lineplot(data=planning_data, ax=ax, x='policy_up_prob', y='initial_discrep', color='blue', linestyle='-', label='Initial, Planning')\n",
        "sns.lineplot(data=learning_data, ax=ax, x='policy_up_prob', y='initial_discrep', color='blue', linestyle='--', label='Initial, Learning')\n",
        "sns.lineplot(data=planning_data, ax=ax, x='policy_up_prob', y='final_discrep', color='black', linestyle='-', label='Final, Planning')\n",
        "sns.lineplot(data=learning_data, ax=ax, x='policy_up_prob', y='final_discrep', color='black', linestyle='--', label='Final, Learning')\n",
        "plt.legend()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/home/taodav/Documents/grl/venv/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "metadata": {
        "debugger": true
      },
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}